{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398a9918",
   "metadata": {},
   "source": [
    "# The Prediction Analysis of Available Bikes and Stands\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This file is only about the implement of the prediction analysis of available bikes and stands both at a given bike station and on a given date.\n",
    "\n",
    "## 1 The Data\n",
    "\n",
    "In our application, our web crawler crawls the data from the bike web and the weather web every five minutes, and the data from the bike web and that from the weather web are immediately merged into one table， named 'real_time'， after being captured. At the same time, the rows in the real_time table are added into a table named 'completetable'. Thus, at any time, there is a 'real_time' table, from which we can obtain the real time data of bike stations and weather, while all the historical data are stacked in the 'completetable' table. Any row in these data holds the data of bike station and of weather matched by time.\n",
    "\n",
    "Training the prediction model need the data from the 'completetable' table will be used. Therefore, firstly I will fetch the data from the 'completetable' table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf2fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import holidays\n",
    "\n",
    "# The configuration of AWS RDS MySQL\n",
    "user = 'admin'\n",
    "password = '00000000'\n",
    "host = 'dbbikes.ci3iggfwlke6.eu-west-1.rds.amazonaws.com'\n",
    "port = 3306\n",
    "database = 'dbbikes'\n",
    "\n",
    "# create the link to Database\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf0cbe",
   "metadata": {},
   "source": [
    "The dependent variables we will predict are the numbers of the available bikes and the spare stands at a given station, that is, 'available_bikes' and 'available_bike_stands', respectively.\n",
    "\n",
    "The independent variables we use to make predictions consist of two three-groups: the features of the bike station, the features of the weather and the time.\n",
    "\n",
    "The features of the bike station:  \n",
    ">number - number of the station. This is NOT an id, thus it is unique only inside a contract;  \n",
    ">banking - indicates whether this station has a payment terminal;  \n",
    ">bonus - indicates whether this is a bonus station.\n",
    "\n",
    "The features of the weather:  \n",
    ">weather_main - Group of weather parameters (Rain, Snow, Extreme etc.)\n",
    ">temp -  Temperature.\n",
    ">wind_speed - Wind speed\n",
    "\n",
    "The time stamp:  \n",
    ">timestamp: the update time  \n",
    "The time stamp will be converted to the variables of date,of weekday, of hour, and of holiday indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420d5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data table from database on AWS\n",
    "table_name = 'completedata'\n",
    "dfAll = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6115e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out the needed feature\n",
    "df = dfAll[['available_bikes', 'available_bike_stands', 'banking', 'number', 'bonus', 'weather_main', 'temp', 'wind_speed', 'timestamp']].copy()\n",
    "\n",
    "# retrieve 'yyyy-mm-dd', 'hour', 'weekday', 'holiday'\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['weekday'] = df['date'].dt.day_name()\n",
    "ie_holidays = holidays.IE()\n",
    "df['holiday'] = df['date'].dt.date.apply(lambda x: x in ie_holidays)\n",
    "\n",
    "# take out the needed columns\n",
    "df = df[['available_bikes', 'available_bike_stands', 'banking', 'number', 'bonus', 'weather_main', 'temp', 'wind_speed', 'hour', 'weekday', 'holiday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea4f3e",
   "metadata": {},
   "source": [
    "# 2 Data Preparation\n",
    "\n",
    "We process the data for the consequent regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277af5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6fa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out independent features and dependent variable\n",
    "X = df[['hour', 'number', 'weekday', 'holiday', 'weather_main', 'banking', 'bonus', 'wind_speed', 'temp']].copy()\n",
    "y = df[['available_bikes', 'available_bike_stands']].copy()\n",
    "\n",
    "# convert categorical variables to one-hot coded variables\n",
    "X[['hour', 'number', 'weekday', 'holiday', 'weather_main', 'banking', 'bonus']] = X[['hour', 'number', 'weekday', 'holiday', 'weather_main', 'banking', 'bonus']].astype(str)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['hour', 'number','weekday', 'holiday', 'weather_main', 'banking', 'bonus'])\n",
    "\n",
    "# divide data into training data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "547b6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize continuous features\n",
    "scaler = StandardScaler()\n",
    "X_train[['wind_speed', 'temp']] = scaler.fit_transform(X_train[['wind_speed', 'temp']])\n",
    "X_test[['wind_speed', 'temp']] = scaler.transform(X_test[['wind_speed', 'temp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd02121",
   "metadata": {},
   "source": [
    "# 3 Training the  Regression Model\n",
    "\n",
    "Considering the spatial correlation of the bike stations, we pooled all the bike stations' data and use the station id, 'number', as a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd44c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the regression model\n",
    "y_train_bikes = y_train['available_bikes']\n",
    "y_train_stands = y_train['available_bike_stands']\n",
    "lr_bikes = LinearRegression()\n",
    "lr_stands = LinearRegression()\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "lr_bikes.fit(X_train, y_train_bikes)\n",
    "lr_stands.fit(X_train, y_train_stands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e3479",
   "metadata": {},
   "source": [
    "# 4 Evaluating the trained Model\n",
    "\n",
    "We use the test data set to produce the prediction and evaluate the model's performance measured by standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209b3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error for Bikes: 7.876773122824796\n",
      "Standard Error for for Stands: 8.067956938441425\n"
     ]
    }
   ],
   "source": [
    "# compute prediction on the test data\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "y_pred_bikes = lr_bikes.predict(X_test)\n",
    "y_pred_stands = lr_stands.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using Mean Squared Error\n",
    "y_test_bikes = y_test['available_bikes']\n",
    "y_test_stands = y_test['available_bike_stands']\n",
    "\n",
    "# compute the standard deviance\n",
    "mse_bikes = mean_squared_error(y_test_bikes, y_pred_bikes)\n",
    "ste_bikes = np.sqrt(mse_bikes)\n",
    "\n",
    "mse_stands = mean_squared_error(y_test_stands, y_pred_stands)\n",
    "ste_stands = np.sqrt(mse_stands)\n",
    "\n",
    "print(\"Standard Error for Bikes:\", ste_bikes)\n",
    "print(\"Standard Error for for Stands:\", ste_stands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59f08f",
   "metadata": {},
   "source": [
    "# 5 Saving the trained model\n",
    "\n",
    "This model will be updated with new data once a month. When the model is trained, it will be saved for being called by the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d160d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Record the order of the features in training data set, \n",
    "# which will be used to rearrange the columns in the forecasting data\n",
    "feature_order = list(X_train.columns) \n",
    "\n",
    "# save the trained models of the available bikes and of the spare stands\n",
    "# save the order of the features in training data set,\n",
    "# save the scaler for standarizing the continuous features\n",
    "models = {'lr_bikes': lr_bikes, 'lr_stands': lr_stands,  'scaler':scaler, 'feature_order': feature_order}\n",
    "\n",
    "# create the path to save the model.\n",
    "file_dir = 'D:\\PythonProjects\\DublinBike'\n",
    "\n",
    "file_path = os.path.join(file_dir, 'models.pkl')\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13004f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
